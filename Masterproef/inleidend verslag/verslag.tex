\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\title{Verslag 'Live actieherkenning met de Kinect sensor in Python'}


\begin{document}
   \maketitle

   \section{Bestaande situatie en probleemstelling}
    Om de Kinect sensor aan te spreken bestaan er momenteel nuttige SDKs voor diverse programmeertalen zoals C++, C\# en Python. Wat alle huidige bestaande SDKs bezitten, is de mogelijkheid om aan de kinect zijn huidig beeld op te vragen en dit te tonen op een scherm. Wat ze echter niet kunnen, is de \underline{mogelijkheid om deze informatie te bewaren}. Dit is echter een vereiste indien er live actieherkenning nodig is. De Kinect moet verschillende acties aanleren met behulp van machine learning, en dit kan enkel gerealiseerd worden indien men beschikt over bruikbare data. 
   \section{Doelstelling}
   Er zijn twee doelen te bereiken met deze masterproef:
   \begin{enumerate}
    \item Een Python implementatie die de Kinect sensor kan aanspreken en de beelden die het genereerd kan opslaan. Als basis zou de bestaande open source bibliotheek PyKinect\footnote{\url{https://github.com/Microsoft/PTVS/wiki/PyKinect}} gebruikt worden.
    \item Met behulp van machine learning zouden er eenvoudige handelingen (bv. zwaaien, bukken, springen, ...) door de Kinect sensor moeten gedetecteerd worden, alsook de naam van de handeling tonen op een uitvoerapparaat. Dit prototype zou dan gebruikt kunnen worden op opendeurdagen om de aandacht van nieuwe studenten aan te trekken.
   \end{enumerate}
   Het eindresultaat is een werkend prototype, dat een bepaalde verzameling van eenvoudige handelingen correct kan herkennen. Het prototype moet ook uitbreidbaar zijn, zodat er nadien eenvoudig nieuwe handelingen kunnen toegevoegd worden. De beelden die de kinect registreert zullen ook beschikbaar zijn in een databank.

\end{document}