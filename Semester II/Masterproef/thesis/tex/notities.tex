\chapter{notities}


\section{papers}
\begin{itemize}
	\item Bron \cite{Wang2014}
	\begin{itemize}
		\item Actieherkenning en actiedetectie systeem voor temporally untrimmed videos door de combinatie van motion en appearance features.
		\begin{itemize}
			\item Motion feature = Fisher vector representatie met dense trajectories
			\item Appearance feature: deep convolutional neural network
		\end{itemize}
	\end{itemize}
	\item Bron \cite{Kang2016}
	\begin{itemize}
		\item Actieherkenning = het herkennen van een actie binnen een goed gedefinieerde omgeving 
		\item Actiedetectie = het herkennen en lokaliseren van acties(begin, duratie en einde) in de ruimte en de tijd
		\item training set = wordt gebruikt om classifier te trainen
		\item validation set = optioneel, bevat andere data dan de training set om de classifier te optimaliseren
		\item testing set = testen van de classifier (performance)
		\item Drie manieren om dataset op te splitsen in deze drie sets:
		\begin{itemize}
			\item voorgedefinieerde split: De dataset wordt opgesplitst  in twee of drie delen zoals de auteurs van die dataset dat vermelden
			\item n-voudige cross-validatie: Verdeeld de dataset in n gelijkvoudige stukken. Hierbij worden er (n-1)/n  percentage van de videos gebruikt om te trainen, en dan de overige 1/n om te testen. Dit proces wordt n keer herhaald, zodat elke video éénmaal gebruikt werd voor te testen
			\item leave-one-out cross-validatie: {\color{green}aangewezen methode indien testdata personen zijn.} 1 persoon wordt als testset beschouwd. De overige $n - 1$ personen is de training set.
		\end{itemize}
		
		
		\item  om actieklasse te bepalen = features extraheren en in classifier steken $\rightarrow$ classifier bepaalt actieklasse
		\item Temporally untrimmed video = delen van de video bevatten GEEN ENKELE actie. Variaties van dezelfde actie kan op hetzelfde moment voorkomen
		
		\item THUMOS challenge:
		\item 2015 $\rightarrow$ slechts één team heeft detection challenge geprobeerd
		
		\item 	Classificatietaak: de lijst van acties geven die in een lange, niet getrimde video voorkomen
		\item 	Detectietaak: ook de lijst van acties geven PLUS de plaats in tijd waar ze voorkomen
	\end{itemize}

	\item Bron \cite{Shotton2011}
	gaat eerder over hoe het skelet bepaalt wordt
	\begin{itemize}
		\item voorstel van een methode om op een accurate manier de 3D posities van de joints te bepalen, vanuit slechts één dieptebeeld, zonder temporale informatie
		\item Het bepalen van lichaamsdelen is invariant van pose, lichaamsbouw, kleren, etc...
		\item Kan runnen aan 200 fps
		\item Wordt effectief gebruikt in de Kinect software (onderzoeksteam is van Microsoft)
		\item Een dieptebeeld wordt gesegmenteerd in verschillende lichaamsdelen, aangegeven door een kleur, op basis van een kansfunctie; Elke pixel van het lichaam wordt apart behandeld en gekleurd. Een verzameling van dezelfde kleuren wordt een joint
		\item Aangezien tijdsaspect weg is, is er enkel interesse in de statische poses van een frame. Verschillen van pose in twee opeenvolgende frames is miniscuul zodat die genegeerd worden
	\end{itemize}


	\item Bron \cite{Li2010} (pre-kinect era)
	\begin{itemize}
		\item Actieherkenning met behulp van reeksen van dieptebeelden
		\item Gaan ervan uit dat efficiënte tracking van skeletbeelden nog niet mogelijk is. (is gepubliceerd zelfde jaar dat Kinect beschikbaar was, 2010)
		\item Hun oplossing is dus niet gebaseerd op het tracken van de skeletbeelden
	\end{itemize}

	\item Bron \cite{Zhao2017}
	\begin{itemize}
		\item Probleem: output van de actiecategorie EN de start en eind tijd van de actie. 
		\item Ze beweren dat actieherkenning reeds goed opgelost is, maar niet actiedetectie. Hun definities zijn: 
		\begin{itemize}
			\item Actieherkenning: De effectieve actieherkenning indien het systeem weet wanneer hij moet herkennen
			\item Actiedetectie: een langdurige video, waarbij de start en stop van een actie niet gedefinieerd zijn = untrimmed video ( videos waarbij er meerdere acties op hetzelfde moment kunnen voorkomen, alsook een irrelevante achtergrond). {\color{green} sluit heel goed aan op onze masterproef}
		\end{itemize}
		\item Uitdaging in bestaande oplossingen: groot aantal onvolledige actiefragmenten. Voorbeelden:
		\begin{itemize}
			\item Bron \cite{Singh2016}:
			\begin{itemize}
				\item maakt gebruik van \textbf{untrimmed classificatie}: de top $k = 3$ (bepaalt via cross-validation) labels worden voorspelt door globale video-level features. Daarna worden frame-level binaire classifiers gecombineerd met dynamisch programmeren om de activity proposals (die getrimmed zijn) te genereren. Elke proposal krijgt een label, gebaseerd op de globale label.
			\end{itemize}
				\item Bron \cite{Yuan2016}:
			\begin{itemize}
				\item Spreekt over de onzekerheid van het voorkomen van een actie en de moeilijkheid van het gebruik van de continue informatie

				\item Pyramid of Score Distribution Feature (PSDF) om informatie op meerdere resoluties op te vangen
				\item PSDF in combinatie met Recurrent Neural networks bieden performantiewinst in untrimmed videos.
				\item Onbekende parameters: actielabel, actieuitvoering, actiepositie, actielengte
				\item Oplossing? Per frame een verzameling van actielabels toekennen, gebruik makend van huidige frame actie-informatie en inter-frame consistentie = PSDF
	
			\end{itemize}
		
		\end{itemize}
		\item De moeilijkheid is: start, einde en duur van de actie te bepalen.
		\item Hun oplossing is \textbf{Structured Segment Network}:
		\begin{itemize}
			\item input: video
			\item output: actiecategorieën en de tijd wanneer deze voorkomen
			\item Drie stappen:
			\begin{enumerate}
				\item Een "proposal method",  om een verzameling van "temporal proposals", elk met een variërende duur en hun eigen start en eind tijd.  Elke proposal heeft drie stages: \textit{starting, course} en \textit{ending}. 
				\item Voor elke proposal wordt er STPP (structured temporal pyramid pooling) toegepast door (1) de proposal op te splitsen in drie delen; (2) temporal pyramidal representaties te maken voor elk deel; (3) een globale representatie maken voor de hele proposal.
				\item Twee classifiers worden gebruikt: herkennen van de actie en de "volledigheid" van de actie nagaan.
			\end{enumerate}
		\end{itemize}
	\end{itemize}

	\item Bron \cite{Huang2018}
	\begin{itemize}
		\item Temporal action detection = moet enerzijds detecteren of al dan niet een actie voorkomt, en anderzijds hoelang deze actie duurt, wat een uitdaging is bij untrimmed videos.
		\item Veel moderne aanpakken gaan als volgt te werk: eerst wordt er klasse-onafhankelijke proposals gegenereerd door 
	\end{itemize}

	\item Bron \cite{Deboeverie2016}
	\begin{itemize}
		\item Sliding window: laatste 30 frames bijhouden in buffer om hoge zekerheid van classificatie te voorzien; met majority voting de actie bepalen die het meeste voorkomt. 
		\item Classifier: random forests. Beslissingsbomen aanmaken via ID3 algoritme
	\end{itemize}

	\item Bron \cite{Suolan2017}
	\begin{itemize}
		\item Depth-based action recognition.
		\item \textit{key frames} worden geproduceerd uit skeletsequenties door gebruik te maken van de joints als \textbf{spatial-temporal interest points (STIPs)}. Deze worden gemapt in een dieptesequentie om een actie sequentie te representeren. De contour van de persoon wordt per frame bepaald. Op basis van deze contour en de tijd worden features opgehaald. Als classifier gebruiken ze een \textit{extreme learning machine}
		\item Voordeel van key frames: ze bevatten de meest informatieve frames. Twee methodieken om de key frames op te halen:
		\begin{enumerate}
			\item \textbf{Interframe difference}: een nieuwe key-frame wordt gekozen als het verschil tussen twee frames een bepaald threshold overschrijft.
			\item \textbf{Clustering}: groeperen van frames die op elkaar lijken op basis van low-level features. Uit die groep wordt dan de keyframe genomen, die het dichtst bij het centrum van dat cluster ligt.
		\end{enumerate}
		\item Zij gebruiken het 'opgenomen verschil': Een positie van een joint $P_{i,j}$ met $i$ het frame index en $j$ de joint index, kan gelijkgesteld worden als  $P_{i, j} = {x_{i, j}, y_{i, j}, z_{i, j}}$
		
		Het opgenomen verschil is dan:
		
		$$D_i = \sum_{j = 1}^{n} || P_{i, j} - P_{i - 1, j}||^2$$
		met $||\cdot||$ de euclidische afstand en $n$ het aantal joints.
		
		\item key frames worden dan gekozen op basis van maximum of minimum $D_i$ binnen een sliding window. Een probleem: $D_i$ is vrij laag voor de eerste en laatste aantal frames. De key frames worden dus eerder gecentraliseerd en kan de sequentie niet accuraat bepaalt worden. Stapsgewijze oplossing:
		\begin{enumerate}
			\item Voor een video met $N$ frames: neem de som van $D_i$ van $i = 2$ tot $i = N$:
			$$D_N = \sum_{i = 2}^{N}D_i$$
			\item Bepaal een aantal key frames $K$ en bereken het gemiddelde van incrementen:
			
			$$D_{avg} = D_N / K$$
			
			\item Voor $i = 2$ tot $i = L$ wordt het verschil berekent:
			
			$$W_L = D_L - k * D_{avg}, k \in K$$
			
			zodat er een verzameling ${W_L}$ is. Het minimum van deze set wordt de key frame.
		\end{enumerate}
		\item Features op basis van contour
		\item Actieherkenning met neurale netwerken (EXTREME LEARNING)
		\item \textbf{Samenvatting:}
		\begin{itemize}
			\item Actionherkenningsmethode voor kinect.
			\item Features op basis van menselijke contour van een keyframe uit een dieptebeeld. Als constraint is er het temporaal verschil.
			\item 'multi-hidden layer extreme learning machine' voor classificatie
		
		\end{itemize}
		
	\end{itemize}

	\item Bron \cite{Carlsson2001}
	\begin{itemize}
		\item Een bepaalde actie kan onderverdeeld worden in een sequentie van poses.
	\end{itemize}	

	\item Bron \cite{Vezzani2010}
	\begin{itemize}
		\item HMM laten toe om de temporale evolutie te modelleren.
		\item De \textbf{feature set} en \textbf{emission probability function} moeten goed gedefinieerd zijn. 
		\item Gegeven een set $C$ van actie classes $\Lambda = \lambda^1 ... \lambda^C$, zoek de klasse $\lambda^*$ die de kans op $P(\lambda|O)$ maximaliseert met $O = \{o_1 ... o_T\}$ de frame observaties.
		\item Een HMM voor elke actie. Classificatie voor een observatiereeks $O$ wordt uitgevoerd door het model te pakken met de hoogste waarschijnlijkheid:
		
				
		$$\lambda^* = \arg \max_{1\leq c\leq C} \big[P(O|\lambda^c)\big]$$
		\item Twee verschillende features gebruikt:
		\begin{itemize}
			\item Projection histograms
			\item Shape descriptors
		\end{itemize}
	\end{itemize}
\end{itemize}



\section{Machine learning}
\subsection{Features}
\begin{itemize}
	\item Een \textbf{feature} is een individueel, meetbare eigenschap of karakteristiek van een object dat geobserveerd wordt.
	\item Eigenschappen:
	\begin{itemize}
		\item Informatief: de informatiewinst van de feature moet hoog zijn
		\item Discriminative: op basis van de feature moet het eenvoudig zijn om het onderscheid te maken tussen de verschillende klassen
		\item Onafhankelijk: De feature op zich mag van geen andere feature of meetwaarde van dezelfde feature afhangen.


	\end{itemize}
	\item Een \textbf{sparse feature discriptor} heeft een variabel aantal features. Een \textbf{dense feature descriptor} heeft een vast aantal features.
	\item \textbf{Feature extraction} ($\equiv$ dimensionality reduction) is het verzamelen van features uit ruwe data zodat deze kunnen gebruikt worden als feature vector bij een classifier. 
	\item Een \textbf{feature vector} is een $n$-dimensionale vector van \underline{numerieke} features.
	\item De \textbf{feature space} ($\equiv$ vectorruimte) beschrijft de ruimte waarin de features zich bevinden. (bv 3 verschillende features = $\mathcal{R}^3$)
	\item \textbf{Feature construction} is het maken van nieuwe features op basis van reeds bestaande features. De mapping is een functie $\phi$, van $\mathcal{R}^n$ naar $\mathcal{R}^{n + 1}$, met $f$ de geconstrueerde feature op basis van bestaande features, bv $f = x_1/x_2$.
	
	$$\phi(x_1, x_2, ..., x_n) = (x_1, x_2, ... x_n, f)$$

\end{itemize}
\subsection{Classifier}
\begin{itemize}
	\item Identificeren tot welke klasse een \underline{nieuwe} observatie behoort, gebaseerd op een training set waarvan de klassen wel gekend zijn.
	\item \textbf{Lineaire classifiers} geven aan elke klasse $k$ een score op basis van de combinatie van de feature vector met een gewichtenvector met het scalair product.  De gekozen klasse is dan die met de hoogste score. Eenvoudiger geschreven:	
	$$
	score(X_i, k) = \beta_k \cdot X_i
	$$
	\begin{itemize}
		\item $X_i$ = de feature vector voor instantie $i$
		\item $\beta_k$ = de gewichtenvector voor klasse $k$
	\end{itemize}
	\item \todo{later onderzoeken}
	\item \textbf{Support Vector machines}
	\item \textbf{Random forests}
	\item \textbf{Boosting}
\end{itemize}




\subsection{Hidden Markov Model}
\label{sec:hidden_markov_model}
Bron \cite{Ramage2007}
\subsubsection{Markov model}

\begin{itemize}
	\item Markov process = stochastisch process met volgende eigenschappen:
	\begin{itemize}
		\item Het aantal toestanden $S = \{s_1, s_2, ... s_{|S|}\}$ is eindig.
		\item Observatie van een sequentie over de tijd $\vec{z} \in S^T$
		
		Voorbeeld: 
		
		$S = \{sun, cloud, rain\}$ met $|S| = 3$ en $\vec{z} = \{z_1=S_{sun},z_2=S_{cloud},z_3=S_{cloud},z_4=S_{rain},z_5=S_{cloud}\}$ met $T = 5$.
		\item Markov Assumpties:
		\begin{enumerate}
			\item Een toestand is enkel afhankelijk van de vorige toestand (\textbf{Markov Property}).
			
			$$P(z_t | z_{t - 1},z_{t-2}, ..., z_1) = P(z_t|z_{t-1})$$
			\item De waarschijnlijk is constant in de tijd
			
			$$P(z_t|z_{t - 1}) = P(z_2|z_1); t \in 2 ...T$$
		\end{enumerate}
		\item Beginstaat $z_0 \equiv s_0$.
		\item Transitiematrix $A \in \mathbb{R}^{(|S| + 1)\times(|S| + 1)}$, met $A_{ij} = P(i \rightarrow j)$, :
		
		$$A = \begin{matrix}
		     & s_0 & s_{sun} & s_{cloud} & s_{rain} \\
		 s_0 & 0 & .33 & .33 & .33 \\
		 s_{sun} & 0 & .8 & .1 & .1 \\
		 s_{cloud} & 0 & .2 & .6 & .2 \\
		 s_{rain} & 0 & .1 & .2 & .7 \\
		\end{matrix}$$
	\end{itemize}

\end{itemize}

\begin{itemize}
	\item Twee vragen die een markov model kunnen oplossen:
	\begin{enumerate}
		\item Wat is de kans op een bepaalde toestandenvector $\vec{z}$?

				$$	P(\vec{z})  = \prod_{t=1}^{T} A_{z_{t-1}z_t}$$

			Stel $\vec{z} = \{z_1=S_{sun},z_2=S_{cloud},z_3=S_{rain},z_4=S_{rain},z_5=S_{cloud}\}$ dan is $P(\vec{z}) = 0.33 \times 0.1 \times 0.2 \times 0.7 \times 0.2 $
		\item Gegeven $\vec{z}$, hoe worden best de parameters van $A$ benaderd zodat de kans op $\vec{z}$ maximaal is.
		$$A_{ij} = \frac{\sum_{t=1}^{T} \{z_{t-1} = s_i \wedge z_t = s_j\}}{\sum_{t=1}^{T} \{z_{t-1} = s_i\}}$$
		
		De maximale kans om van staat $i$ naar $j$ te gaan is het aantal transities van $i$ naar $j$ gedeeld door het totaal aantal keer dat we in $i$ zitten. Met andere woorden: Hoeveel \% zaten we in $i$ als we van $j$ komen.
	\end{enumerate}
\end{itemize}

\subsubsection{Hidden Markov Model}
\begin{itemize}
	\item \gls{ac:hmm} = Veronderstelt een markov process met verborgen toestanden
	\item Bij een HMM: de staat is niet zichtbaar, maar de output is wel zichtbaar.
	\item Formeel:
	\begin{itemize}
		\item Sequentie van geobserveerde outputs $x = \{x_1, x_2, ..., x_T\}$  uit een alfabet $V = \{v_1, v_2, ..., v_{|V|}\}$
		\item Er is ook een sequentie van staten $z =\{z_1, z_2, ... z_T\}$ uit een alfabet $S = \{s_1, s_2, ... s_{|S|}\}$, maar deze zijn \underline{niet zichtbaar}.
		\item Transitiematrix $A_{ij}$ wel bekend.
		\item Kans dat een bepaalde output gegenereerd wordt in functie van de verborgen toestanden:
		
		$$P(x_t = v_k|z_t = s_j) = P(x_t = v_k | x_1, ..., x_T, z_1, ..., z_T) = B_{jk}$$
		
		Matrix $B$ geeft de waarschijnlijkheid dat een verborgen toestand $s_j$ de output $v_k$ teruggeeft.
	\end{itemize}
	\item Vaak voorkomende problemen die opgelost kunnen worden met HMM:
	\begin{itemize}
		\item Gegeven de parameters en geobserveerde data, benader de optimale sequentie van verborgen toestanden.
		\item Gegeven de parameters en geobserveerde data, bereken de kans op die data. $\rightarrow$ Wordt het 'decoding' probleem (\textbf{Viterbi Algoritme}) genoemd en wordt gebruikt bij continue actieherkenning.
		\item Gegeven de geobserveerde data, benader de parameters van $A$ en $B$.
	\end{itemize}
	\item Het \textbf{decoding probleem}: \url{http://jedlik.phy.bme.hu/~gerjanos/HMM/node8.html}
	\begin{itemize}
		\item Zoek de meest waarschijnlijke reeks van toestanden $\vec{z} \in S^T$ voor een verzameling van observaties $\vec{x} \in V^T$.
		
		\item Hoe 'meest waarschijnlijke toestandensequentie' definiëren. Een mogelijke manier is om de meest waarschijnlijke staat $s_t$ voor $x_t$ te berekenen, en alle $q_t$ dier daar aan voldoen te concateneren.
		Andere manier is \textbf{Viterbi algoritme} die de hele toestandensequentie met de grootste waarschijnlijkheid teruggeeft.
		
		\item Hulpvariabele:
		
		$$\delta_t(i) = \max_{\substack{q_1, q_2, ... q_{t-1}}} p\{q_1, q_2, ... q_{t - 1}, q_t = i, o_1, o_2, ... o_{t - 1} | \lambda \}$$
		
		die de hoogste kans beschrijft dat een partiele observatie en toestandensequentie tot $t = t$ kan hebben, wanneer de huidige staat $i$ is.
	\end{itemize}
\end{itemize}


