\chapter{Methodologie}
\label{ch:methodologie}

Ieder persoon heeft een eigen interpretatie van een bepaalde actie. Er kunnen verschillen zijn in snelheid, de positie relatief tot het hele lichaam en zelfs de lichaamsbouw van die persoon. Elk van deze variaties in een algoritme steken is dan ook onbegonnen werk. Daarom maakt elk modern actieherkenningsalgoritme op één of andere manier gebruik van \textit{machine learning}. Op basis van training data wordt een \textit{classifier} getraind die kan voorspellen tot welke klasse een nieuwe observatie behoort. In deze masterproef wordt de skeletinformatie van de Kinect beschouwd als observatie, maar andere observaties zijn ook mogelijk zoals de ruwe kleuren- of dieptebeelden.

Zulke observaties worden getransformeerd naar \textit{features}. Dit zijn meetbare eigenschappen of karakteristieken van het object dat geobserveerd wordt. Deze eigenschappen moeten bovendien voldoende onderscheidend zijn zodat het mogelijk is om de observatie te klasseren. Een feature heeft als doel de originele observatie te reduceren tot bruikbare informatie om op een eenvoudigere manier classificatie uit te voeren. Een \textit{feature vector} vormt een $n$-dimensionale wiskundige vector van features. Elke dimensie van deze vector is een individuele feature en alle features samen vormt de \textit{feature space}. Als voorbeeld van een feature vector zouden de drie-dimensionale coördinaten van elke skeletjoint gekozen kunnen worden. De feature vector voor een frame zou dan, in het geval van 25 joints, 75 dimensies bevatten. Via bestaande features kunnen er nieuwe features aangemaakt worden via \textit{feature construction}. Het proces om een observatie om te vormen tot een feature vector wordt gerealiseerd met \textit{feature detectors} en \textit{feature descriptors}. In functie van computervisie bepaalt een feature detector de locaties waar eventueel interessante pixels kunnen zijn. Een hoekdetector zal de coördinaten van pixels geven waar er hoeken zijn. Een feature descriptor omschrijft de lokale regio rond elk van deze gevonden pixels, zoals bijvoorbeeld de ruwe pixelwaarden in een bepaald bereik.

Een \textit{classifier} verwacht als input zo een feature vector. Het is de taak van een classifier om te bepalen tot welke klasse een nieuwe observatie behoort. In het geval van actieherkenning is de klasse een bepaalde actie, zoals zwaaien, bukken of springen. Een classifier zal bij het bepalen van een klasse ook een zogenaamde \textit{score} geven. Dit is de waarschijnlijkheid dat de voorspelde klasse correct is. Een eenvoudige \textit{lineaire classifier} berekent de score op basis van een lineaire combinatie tussen de feature vector en een speciale gewichtenvector, specifiek voor die klasse en die gebaseerd is op de training data. De voorspelde klasse is dan die met de hoogste score. Er bestaan zowel \textit{supervised} als \textit{unsupervised} classificatiemodellen. Beiden maken gebruik van een leerverzameling; een collectie van voorbeelden waaruit het systeem moet leren. Voor een supervised model wordt het gewenste resultaat meegegeven aan elk object in de leerverzameling. Bij een unsupervised model is dit niet zo, maar er is wel een algemeen idee van wat er moet aangeleerd worden. Een supervised model wordt vaak toegepast op actieherkenning. De leerverzameling bevat videobeelden waarin acties door personen worden uitgevoerd, samen met de gelabelde klasse.


In deze masterproef wordt er gebruik gemaakt van de skeletdata die door de Kinect genereert wordt. Dit is een verzameling van joints waarbij elke joint gekenmerkt wordt door een unieke index, zijn drie-dimensionale coördinaten en zijn relatieve quaternionen. Deze skeletdata kan op allerhande manieren gemanipuleerd worden om nuttige feature vectors te construeren. Er wordt een onderscheid gemaakt tussen \textit{joint-based} en \textit{body-based} features. Joint-based features zien de joints als een verzameling van punten waarbij de joints onafhankelijk van elkaar beschouwd worden (\cite{Hussein2011}, \cite{Lv2006}), via een vast assenstelsel gelokaliseerd worden (\cite{Xia2012}) of via de relatieve posities tussen elk paar joints gekenmerkt worden (\cite{Wang2012b}, \cite{Yang2012}). Body-based features zien het skelet als een geheel van vaste lichaamsdelen die onderling verbonden zijn met elkaar. Deze methoden focussen zich op verbonden paren van lichaamsdelen en modelleren de temporale evolutie met behulp van de hoeken tussen deze lichaamsdelen (\cite{Ofli2012}, \cite{Ohn-Bar2013}, \cite{Deboeverie2016}). 

\todo{In deze masterproef  wordt X en Y gebruikt omdat Z. }

Tabel \ref{table:recognized_actions} geeft een overzicht van de herkende acties en wat hun semantische waarde is. Er wordt een eigen dataset gecreëerd die deze $x$ acties bevat die door $y$ verschillende personen worden uitgevoerd.

{
\begin{table}
	\centering
	\begin{tabular}{p{0.49\textwidth} p{0.49\textwidth}}
		\hline 
		Actie & Betekenis \\
		\hline
		1. Gestrekt rechterarm met handpalm naar de camera gericht & Stop huidige actie \\
		\hdashline
		2. Achteruit zwaaien met de rechterarm & Verplaats in de richting van de gebruiker (vooruit) \\
		\hdashline
		3. Vooruit zwaaien met de rechterarm & Verplaats in de tegenovergestelde richting van de gebruiker (achteruit)\\
		 \hdashline
		4. Naar rechts zwaaien met de rechterarm & Verplaats naar links, vanuit het perspectief van robot (dus naar rechts voor de operator)\\
		\hdashline
		5. Naar links zwaaien met de rechterarm & Verplaats naar rechts, vanuit het perspectief van robot (dus naar links voor de operator) \\
		\hdashline
		6. Gestrekt linkerarm met handpalm naar de camera gericht & Stop huidige actie \\
		\hdashline
		7. Achteruit zwaaien met de linkerarm & Verplaats in de richting van de gebruiker (vooruit) \\
		\hdashline
		8. Vooruit zwaaien met de linkerarm & Verplaats in de tegenovergestelde richting van de gebruiker (achteruit)\\
		\hdashline
		9. Naar rechts zwaaien met de linkerarm & Verplaats naar links, vanuit het perspectief van robot (dus naar rechts voor de operator)\\
		\hdashline
		10. Naar links zwaaien met de linkerarm & Verplaats naar rechts, vanuit het perspectief van robot (dus naar links voor de operator) \\
		\hdashline
		11. Cirkel tekenen &  Rotatie rond de as uitvoeren
	\end{tabular}
	\caption{De herkende acties samen met hun semantische waarde.}
	\label{table:recognized_actions}
\end{table}
}






\iffalse
\begin{itemize}
	\item Basisidee: \textit{key frames} = kan zeker voordeel brengen.
	
	\begin{itemize}
		\item Welke acties herkennen?  
		\item Wat is 'te weinig verschil'? Zie bv \cite{Suolan2017}.
		\item Wanneer gebruikte frames weggooien? Ik beslis welke frames niet opgenomen worden, dus er is vrij veel bias.
		\item Studie hidden markov model $\rightarrow$ zie \ref{sec:hidden_markov_model}
		\item Waarom niet gewoon simpele teller gebruiken om met tijdsaspect om te gaan?
	\end{itemize}

	\item Ander idee: multi-resolutie aanpak (pyramide)
	\begin{itemize}
		\item Aan de top van de piramide: resolutie 0 met slechts 1 frame.
		\item Per niveau wordt het aantal frames met twee verhoogd. Dus op resolutie $r$ beschouwen we  $2r + 1$ frames.
	\end{itemize}

	\item Waarom is dit onderzoek nuttig? 
	\begin{itemize}
		\item Live actieherkenning vereist snelle classificatie
		\item Verlagen van computationele kost
		\item Op voorwaarde dat bepalen van keyframes sneller is dan gewoon elke frame in beschouwing te nemen. 
		\item Wat is live actieherkenning? 
		\begin{itemize}
			\item Er is geen default pose
			\item Er is niet altijd een actor in beeld. Een actor is een persoon waarvan de skeletinformatie beschikbaar is, dus als de kinect correct het skelet kan bepalen van een persoon.
			\item Vanaf dat een actor een actie uitvoert, moet deze vroeg genoeg herkend kunnen worden ($< 1$ seconde, liefst sneller)
			\item De classificatie moet ook kunnen omgaan met het tijdsaspect van de uitgevoerde actie.
		\end{itemize}
	\end{itemize}

	\item Waarom skeletbeelden van de Kinect gebruiken?
	\begin{itemize}
		\item Worden gegenereerd uit dieptebeelden, op een vrij efficiënte manier \cite{Shotton2011}.
		\item Dieptebeelden zijn ongevoelig voor verandering van lichtintensiteit. Ook vormt schaduw geen probleem meer.
		\item Nadelen:
		\begin{itemize}
			\item De kinect mag het enige apparaat in de omgeving zijn die infrarood uitstraalt. Dus kan al enkel indoor gebruikt worden.
			\item mogelijke fouten door ruis in dieptebeelden
		\end{itemize}
		\item Kenmerken:
		\begin{itemize}
			\item Verzameling van joints.
			\item Elke joint wordt voorgesteld door een $3D$ coördinaat.
		\end{itemize}
			
	\end{itemize}

	\item Classificatiemodel pas vastleggen nadat verschillende mogelijkheden getest zijn op dataset.
	\begin{itemize}
		\item Support vector machines
		\item ensemble methoden
		\item \remark{nog geen prioriteit}
	\end{itemize}

\fi
\section{Implementatie}
Er wordt gekozen om de software te implementeren met Python. Python biedt een rijk aanbod van \textit{machine learning tools} die het ontwikkelen van dergerlijke applicaties sterk vereenvoudigen. Om de Kinect aan te spreken wordt er gemaakt van \textit{PyKinectV2}. Dit is een \gls{ac:api} geïmplementeerd die bindings beschikbaarstelt om de Kinect vanuit Python aan te spreken.

  
